name: Infra as Code on Digital Ocean

on:
  push:
    branches:
      - dev
  workflow_dispatch:

env:
  K8S_BOOTUP_TIME_SEC: 60
jobs:
  setup_infra:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: v3.14.0

      - name: Install kubeseal
        uses: digitalservicebund/setup-kubeseal@v1.0.0

      - name: Install envsubst
        run: sudo apt-get update && sudo apt-get install -y gettext

      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DO_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          cd infra-as-code
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Pulumi CLI
        uses: pulumi/actions@v4
        with:
          pulumi-version: latest

      - name: Login to Pulumi
        run: pulumi login
        env:
          PULUMI_ACCESS_TOKEN: ${{ secrets.PULUMI_ACCESS_TOKEN }}

      - name: Set up Pulumi stack
        run: |
          cd infra-as-code
          pulumi stack select prod || pulumi stack init prod
          pulumi config set digitalocean:token ${{ secrets.DO_TOKEN }} --secret
          pulumi refresh --yes
          OUTPUT=$(pulumi stack output k8s_cluster_id || echo "")
          if [ -n "$OUTPUT" ]; then
            echo "K8S_CLUSTER_ID=$OUTPUT" >> $GITHUB_ENV
            echo "âœ… Exported K8S_CLUSTER_ID"
            export K8S_CLUSTER_ID=$OUTPUT
          fi
      - name: D eploy with Pulumi
        run: |
          cd infra-as-code
          pulumi up --yes
          echo "K8S_CLUSTER_ID=$(pulumi stack output k8s_cluster_id)" >> $GITHUB_ENV
          pulumi destroy --remove --yes --color -e
      - name: Save DigitalOcean kubeconfig
        run: |
          cd infra-as-code
          doctl kubernetes cluster kubeconfig save ${{ env.K8S_CLUSTER_ID }}
      - name: Check if k8s nodes ready
        run: |
          echo "lets wait for some time to allow nodes be ready..."
          sleep ${{ env.K8S_BOOTUP_TIME_SEC }}
          export NOT_READY_NODES=$(kubectl get nodes --no-headers | awk '$2 != "Ready"')
          if [ -n "$NOT_READY_NODES" ]; then
            echo "âŒ Some nodes are NotReady:"
            echo "$NOT_READY_NODES"
            exit 1
          else
            echo "âœ… All nodes are Ready."
          fi
      - name: ðŸŒ€à¼„ ðŸ”
        run: |
          kubectl create namespace airflow || echo "airflow namespace exists"
          kubectl create namespace sealed-secrets  || echo "sealed-secrets namespace exists"
          helm repo add sealed-secrets https://bitnami-labs.github.io/sealed-secrets || echo "sealed secrets repo added"
          helm repo update
          helm upgrade --install sealed-secrets-controller sealed-secrets/sealed-secrets --namespace sealed-secrets
          sleep 90
          kubectl get pods -A | grep sealed-secrets || echo "tried to get pods"
          kubectl create secret generic git-credentials --namespace airflow  --dry-run=client --from-literal=GIT_SYNC_USERNAME='${{ secrets.GIT_SYNC_USERNAME }}' --from-literal=GITSYNC_USERNAME='${{ secrets.GIT_SYNC_USERNAME }}' --from-literal=GIT_SYNC_PASSWORD='${{ secrets.GIT_SYNC_PASSWORD }}' --from-literal=GITSYNC_PASSWORD='${{ secrets.GIT_SYNC_PASSWORD }}' --from-literal=password=LOL -o json | kubeseal --namespace airflow --controller-namespace=sealed-secrets --scope=strict --format=yaml > my-secret-sealed.yaml
          kubectl apply -f my-secret-sealed.yaml -n airflow
          export SOCRATA_TOKEN=${{ secrets.SOCRATA_APP_TOKEN }}
          export S3_ACCESS_KEY=${{ secrets.S3_ACCESS_KEY }}
          export S3_SECRET_KEY=${{ secrets.S3_SECRET_KEY }}
          export ICEBERG_PATH=${{ secrets.ICEBERG_PATH }}
          export RAW_DATA_PATH=${{ secrets.RAW_DATA_PATH }}
          envsubst < dag_secrets_template.yaml | kubectl create -f - --dry-run=client -o json | kubeseal--namespace airflow --controller-namespace=sealed-secrets --scope=strict --format=yaml > dag-sealed-secret.yaml
          kubectl apply -f dag-sealed-secret.yaml -n airflow
      - name: ðŸŒ€à¼„ setup
        run: |
          cd infra-as-code/airflow
          export PGKEY=${{ secrets.PGKEY }}
          export AF_FN=${{ secrets.AF_FN }}
          export AF_LN=${{ secrets.AF_LN }}
          export AF_EMAIL=${{ secrets.AF_EMAIL }}
          export AF_USER=${{ secrets.AF_USER }}
          export AF_KEY=${{ secrets.AF_KEY }}
               
          envsubst < airflow_values_template.yaml > airflow_values.yaml
          helm repo add apache-airflow https://airflow.apache.org || echo "airflow repo added"
          helm repo update
          helm upgrade --install airflow apache-airflow/airflow -n airflow --create-namespace -f airflow_values.yaml
      - name: Apply Dag Configs
        run: |
          cd infra-as-code/k8s
          kubectl apply -n airflow -f common_config_map.yaml
          kubectl apply -n airflow -f cubes_job_config_map.yaml
          kubectl apply -n airflow -f ingest_job_config_map.yaml
          sleep 600
      - name: ðŸ”¥Tear down
        if: always()
        run: |
          cd infra-as-code
          pulumi destroy --remove --yes
