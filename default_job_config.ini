[logging]
level = INFO

[job]
target_timezone = America/Chicago

[pull_job]
raw_data_path = /tmp/crash_data
# name vs id
datasets =  {"crashes": {"id": "85ca-t3if", "time_column" : "crash_date"},  "crashes_people": {"id": "u6pd-qa9d", "time_column" : "crash_date"}, "crashes_vehicles": {"id": "68nd-jvt3", "time_column" : "crash_date"}}
timeout_sec = 10
batch_size = 2000
sleep_time_millis = 100
domain = data.cityofchicago.org

[iceberg]
catalog_name = local
catalog_type = hadoop
db = db
wh_path = /tmp/iceberg_crashes

[spark]
spark.local.dir	 = /tmp/spark-temp
spark.master	 = local
spark.driver.memory = 2g
spark.jars.packages = org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.8.1
spark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.sql.session.timeZone = GMT
spark.sql.legacy.parquet.nanosAsLong = true
spark.sql.parquet.timestampNTZ.enabled = true
